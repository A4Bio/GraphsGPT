{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "## Graph Hybridization",
   "metadata": {
    "collapsed": false
   },
   "id": "39acb5484ae93032"
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3ce5e2e66e562",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Configurations",
   "metadata": {
    "collapsed": false
   },
   "id": "547d4eeb7c67f3f5"
  },
  {
   "cell_type": "code",
   "source": [
    "model_name_or_path = \"DaizeDong/GraphsGPT-8W\"\n",
    "smiles_file = \"../../data/examples/zinc_example.txt\"\n",
    "\n",
    "batch_size = 1024\n",
    "num_reference_moles = 1000\n",
    "hybridization_save_dir = \"./hybridization_results\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff1629eeec9e1ca9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load SMILES"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7b4ec9a8877b890"
  },
  {
   "cell_type": "code",
   "source": [
    "with open(smiles_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    smiles_list = f.readlines()\n",
    "smiles_list = [smiles.removesuffix(\"\\n\") for smiles in smiles_list]\n",
    "\n",
    "print(f\"Total SMILES loaded: {len(smiles_list)}\")\n",
    "for i in range(10):\n",
    "    print(f\"Example SMILES {i}: {smiles_list[i]}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a72a9294218b12a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Model & Tokenizer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "782dbc40cecedcf8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from models.graphsgpt.modeling_graphsgpt import GraphsGPTForCausalLM\n",
    "from data.tokenizer import GraphsGPTTokenizer\n",
    "\n",
    "model = GraphsGPTForCausalLM.from_pretrained(model_name_or_path)\n",
    "tokenizer = GraphsGPTTokenizer.from_pretrained(model_name_or_path)\n",
    "\n",
    "print(model.state_dict().keys())\n",
    "print(f\"Total paramerters: {sum(x.numel() for x in model.parameters())}\")"
   ],
   "id": "ec85ceb3f073c0d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate Original Molecules\n",
    "\n",
    "Results will be saved to the \"original\" folder. (Empty image means generation failed)\n",
    "\n",
    "You need to select a target molecule from them for hybridization."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a35d0d48b775d086"
  },
  {
   "cell_type": "code",
   "source": [
    "from utils.operations.operation_list import split_list_with_yield\n",
    "from utils.operations.operation_tensor import move_tensors_to_device\n",
    "from utils.operations.operation_dict import reverse_dict\n",
    "from utils.io import delete_file_or_dir, save_empty_png, save_mol_png\n",
    "\n",
    "# read bond dict\n",
    "bond_dict = tokenizer.bond_dict\n",
    "inverse_bond_dict = reverse_dict(bond_dict)\n",
    "\n",
    "# generate fingerprint tokens & get original results\n",
    "now_sample_num = 0\n",
    "all_fingerprint_tokens = []\n",
    "all_generated_results = []\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print(f\"Generating original molecules...\")\n",
    "with torch.no_grad():\n",
    "    for batched_smiles in split_list_with_yield(smiles_list, batch_size):\n",
    "        inputs = tokenizer.batch_encode(batched_smiles, return_tensors=\"pt\")\n",
    "        move_tensors_to_device(inputs, device)\n",
    "\n",
    "        fingerprint_tokens = model.encode_to_fingerprints(**inputs)  # (batch_size, num_fingerprints, hidden_dim)\n",
    "        generated_results: list = model.generate_from_fingerprints(\n",
    "            fingerprint_tokens=fingerprint_tokens,\n",
    "            bond_dict=bond_dict,\n",
    "            strict_generation=True,\n",
    "            similarity_threshold=0.5,\n",
    "            check_first_node=True,\n",
    "            check_atom_valence=False,\n",
    "            fix_aromatic_bond=True,\n",
    "            use_cache=False,\n",
    "            save_failed=False,\n",
    "            show_progress=True,\n",
    "            verbose=True,\n",
    "        )\n",
    "\n",
    "        # limit the number of samples\n",
    "        this_sample_num = fingerprint_tokens.shape[0]\n",
    "        append_sample_num = min(this_sample_num, num_reference_moles - now_sample_num)\n",
    "        if append_sample_num > 0:\n",
    "            now_sample_num += append_sample_num\n",
    "            all_fingerprint_tokens.append(fingerprint_tokens[:append_sample_num])\n",
    "            all_generated_results.extend(generated_results[:append_sample_num])\n",
    "        if append_sample_num < this_sample_num:\n",
    "            print(\"Max sample num reached, stopping forwarding.\")\n",
    "            break\n",
    "\n",
    "all_fingerprint_tokens = torch.cat(all_fingerprint_tokens, dim=0)\n",
    "num_fingerprint_tokens = fingerprint_tokens.shape[1]\n",
    "print(f\"Number of samples is {all_fingerprint_tokens.shape[0]}\")\n",
    "print(f\"Number of fingerprints for each sample is {num_fingerprint_tokens}\")\n",
    "\n",
    "# save generated original results to disk as reference molecules\n",
    "success_cnt = 0\n",
    "invalid_cnt = 0\n",
    "fail_cnt = 0\n",
    "save_smiles_list = []\n",
    "\n",
    "orignial_moles_save_dir = os.path.join(hybridization_save_dir, \"original\")\n",
    "delete_file_or_dir(orignial_moles_save_dir)\n",
    "os.makedirs(orignial_moles_save_dir)\n",
    "\n",
    "for i, result in tqdm(enumerate(all_generated_results), desc=\"Saving molecule images\"):\n",
    "    save_img_path = os.path.join(orignial_moles_save_dir, f\"{i}.png\")\n",
    "\n",
    "    if result is not None:\n",
    "        input_ids = result[\"input_ids\"]\n",
    "        graph_position_ids_1 = result[\"graph_position_ids_1\"]\n",
    "        graph_position_ids_2 = result[\"graph_position_ids_2\"]\n",
    "        identifier_ids = result[\"identifier_ids\"]\n",
    "\n",
    "        mol = tokenizer._convert_token_tensors_to_molecule(input_ids, graph_position_ids_1, graph_position_ids_2, identifier_ids, inverse_bond_dict)\n",
    "\n",
    "        if mol is None:\n",
    "            save_smiles_list.append(None)\n",
    "            save_empty_png(save_img_path)\n",
    "            invalid_cnt += 1\n",
    "        else:\n",
    "            smiles = tokenizer._convert_molecule_to_standard_smiles(mol)\n",
    "            save_smiles_list.append(smiles)\n",
    "            save_mol_png(mol, save_img_path)\n",
    "            success_cnt += 1\n",
    "    else:\n",
    "        save_smiles_list.append(None)\n",
    "        save_empty_png(save_img_path)\n",
    "        fail_cnt += 1\n",
    "\n",
    "# save statistics\n",
    "with open(os.path.join(orignial_moles_save_dir, \"count.txt\"), 'a') as f:\n",
    "    f.write(f\"Success count: {success_cnt}\\n\")\n",
    "    f.write(f\"Invalid count: {invalid_cnt}\\n\")\n",
    "    f.write(f\"Fail count: {fail_cnt}\\n\")\n",
    "\n",
    "with open(os.path.join(orignial_moles_save_dir, \"smiles.txt\"), 'a') as f:\n",
    "    for smiles in save_smiles_list:\n",
    "        f.write(f\"{smiles}\\n\")\n",
    "\n",
    "print(f\"Results saved to {orignial_moles_save_dir}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73ebe4271d62c9a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Select Target Molecule to Perform Hybridization\n",
    "\n",
    "Select a target molecules from the original molecules for hybridization!\n",
    "\n",
    "It is better that selected molecules are generated successfully (corresponding images are not empty).\n",
    "\n",
    "You also need to set the indices of fingerprint tokens to hybrid. You can check the clustering results for reference. A simple method is to hybrid the tokens where the target molecule's cluster possessed obvious features (e.g., all molecules in the cluster share the same functional group).\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c23fc5b9985ddd1"
  },
  {
   "cell_type": "code",
   "source": [
    "# You can change the index according to the results of molecules\n",
    "target_mole_index = 344\n",
    "\n",
    "# To hybrid multiple tokens at a time, separate the indices with \",\"\n",
    "hybrid_token_index_list = \"0,1,2\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f291918e3687b84d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate Hybrid Molecules\n",
    "\n",
    "Results will be saved to the \"hybrid\" folder. (Empty image means generation failed)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6c915d150a5a3be"
  },
  {
   "cell_type": "code",
   "source": [
    "# get target fingerprint tokens\n",
    "target_fingerprint_tokens = all_fingerprint_tokens[target_mole_index].unsqueeze(0)  # (1, num_fingerprints, embed_size)\n",
    "\n",
    "# hybrid fingerprint tokens\n",
    "hybridization_ids = [int(id) for id in hybrid_token_index_list.split(\",\")]\n",
    "assert all(id < num_fingerprint_tokens for id in hybridization_ids)\n",
    "hybridization_ids = torch.tensor(hybridization_ids, device=device, dtype=torch.int64)\n",
    "\n",
    "all_hybrid_fingerprint_tokens = fingerprint_tokens.clone()\n",
    "all_hybrid_fingerprint_tokens[:, hybridization_ids, :] = target_fingerprint_tokens[:, hybridization_ids, :]\n",
    "\n",
    "# generate hybrid molecules\n",
    "print(f\"Generating for fingerprint token hybridization...\")\n",
    "all_hybrid_generated_results: list = model.generate_from_fingerprints(\n",
    "    fingerprint_tokens=all_hybrid_fingerprint_tokens,\n",
    "    bond_dict=bond_dict,\n",
    "    strict_generation=True,\n",
    "    similarity_threshold=0.5,\n",
    "    check_first_node=True,\n",
    "    check_atom_valence=False,\n",
    "    fix_aromatic_bond=True,\n",
    "    use_cache=False,\n",
    "    save_failed=False,\n",
    "    show_progress=True,\n",
    "    verbose=True,\n",
    ")\n",
    "all_hybrid_generated_results = [move_tensors_to_device(result, \"cpu\") for result in all_hybrid_generated_results]\n",
    "\n",
    "# save generated hybrid results to disk\n",
    "success_cnt = 0\n",
    "invalid_cnt = 0\n",
    "fail_cnt = 0\n",
    "save_smiles_list = []\n",
    "\n",
    "hybrid_moles_save_dir = os.path.join(hybridization_save_dir, f\"hybrid{hybrid_token_index_list.replace(',', '_')}\")\n",
    "delete_file_or_dir(hybrid_moles_save_dir)\n",
    "os.makedirs(hybrid_moles_save_dir)\n",
    "\n",
    "for i, result in tqdm(enumerate(all_hybrid_generated_results), desc=\"Saving molecule images\"):\n",
    "    save_img_path = os.path.join(hybrid_moles_save_dir, f\"{i}.png\")\n",
    "\n",
    "    if result is not None:\n",
    "        input_ids = result[\"input_ids\"]\n",
    "        graph_position_ids_1 = result[\"graph_position_ids_1\"]\n",
    "        graph_position_ids_2 = result[\"graph_position_ids_2\"]\n",
    "        identifier_ids = result[\"identifier_ids\"]\n",
    "\n",
    "        mol = tokenizer._convert_token_tensors_to_molecule(input_ids, graph_position_ids_1, graph_position_ids_2, identifier_ids, inverse_bond_dict)\n",
    "\n",
    "        if mol is None:\n",
    "            save_smiles_list.append(None)\n",
    "            save_empty_png(save_img_path)\n",
    "            invalid_cnt += 1\n",
    "        else:\n",
    "            smiles = tokenizer._convert_molecule_to_standard_smiles(mol)\n",
    "            save_smiles_list.append(smiles)\n",
    "            save_mol_png(mol, save_img_path)\n",
    "            success_cnt += 1\n",
    "    else:\n",
    "        save_smiles_list.append(None)\n",
    "        save_empty_png(save_img_path)\n",
    "        fail_cnt += 1\n",
    "\n",
    "# save statistics\n",
    "with open(os.path.join(hybrid_moles_save_dir, \"count.txt\"), 'a') as f:\n",
    "    f.write(f\"Success count: {success_cnt}\\n\")\n",
    "    f.write(f\"Invalid count: {invalid_cnt}\\n\")\n",
    "    f.write(f\"Fail count: {fail_cnt}\\n\")\n",
    "\n",
    "with open(os.path.join(hybrid_moles_save_dir, \"smiles.txt\"), 'a') as f:\n",
    "    for smiles in save_smiles_list:\n",
    "        f.write(f\"{smiles}\\n\")\n",
    "\n",
    "print(f\"Results saved to {hybrid_moles_save_dir}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51106da6ac5f75fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "All done.\n",
    "You can check the saved files for further analysis."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68a5f465ea8f8c17"
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b09c5999ffd5f9b6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
