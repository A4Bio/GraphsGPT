{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Pipeline of GraphsGPT with Hugging Face Transformers",
   "metadata": {
    "collapsed": false
   },
   "id": "3e188af549c37dc3"
  },
  {
   "cell_type": "markdown",
   "source": "### Configurations",
   "metadata": {
    "collapsed": false
   },
   "id": "e5ecf87e00701167"
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "model_name_or_path = \"DaizeDong/GraphsGPT-8W\"\n",
    "smiles_file = \"../data/examples/zinc_example.txt\"\n",
    "\n",
    "batch_size = 1024\n",
    "max_batches = 4\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef4b44c94c086bd1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load SMILES"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84357216224aed01"
  },
  {
   "cell_type": "code",
   "source": [
    "with open(smiles_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    smiles_list = f.readlines()\n",
    "smiles_list = [smiles.removesuffix(\"\\n\") for smiles in smiles_list]\n",
    "\n",
    "print(f\"Total SMILES loaded: {len(smiles_list)}\")\n",
    "for i in range(10):\n",
    "    print(f\"Example SMILES {i}: {smiles_list[i]}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c903203360b16",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Model & Tokenizer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4263d29cbbe85ea1"
  },
  {
   "cell_type": "code",
   "source": [
    "from models.graphsgpt.modeling_graphsgpt import GraphsGPTForCausalLM\n",
    "from data.tokenizer import GraphsGPTTokenizer\n",
    "\n",
    "model = GraphsGPTForCausalLM.from_pretrained(model_name_or_path)\n",
    "tokenizer = GraphsGPTTokenizer.from_pretrained(model_name_or_path)\n",
    "\n",
    "print(model.state_dict().keys())\n",
    "print(f\"Total paramerters: {sum(x.numel() for x in model.parameters())}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eed2630d3a5bf75a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Encode SMILES into Fingerprint Embeddings (Graph Words)",
   "metadata": {
    "collapsed": false
   },
   "id": "6a43509f85c9ef0c"
  },
  {
   "cell_type": "code",
   "source": [
    "from utils.operations.operation_tensor import move_tensors_to_device\n",
    "from utils.operations.operation_list import split_list_with_yield\n",
    "\n",
    "batch_count = 0\n",
    "fingerprints_lists = []\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batched_smiles in split_list_with_yield(smiles_list, batch_size):\n",
    "        inputs = tokenizer.batch_encode(batched_smiles, return_tensors=\"pt\")\n",
    "        move_tensors_to_device(inputs, device)\n",
    "\n",
    "        fingerprint_tokens = model.encode_to_fingerprints(**inputs)  # (batch_size, num_fingerprints, hidden_dim)\n",
    "        fingerprints_lists.append(fingerprint_tokens)\n",
    "\n",
    "        batch_count += 1\n",
    "        if batch_count >= max_batches:\n",
    "            break\n",
    "\n",
    "print(f\"Encoded total {batch_count * batch_size} molecules\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7a04d04186c8a9c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Recover Molecule Sequences through Generation",
   "metadata": {
    "collapsed": false
   },
   "id": "3ec3683b0fa19abb"
  },
  {
   "cell_type": "code",
   "source": [
    "all_results = []\n",
    "\n",
    "for fingerprints in fingerprints_lists:\n",
    "    generation_result = model.generate_from_fingerprints(\n",
    "        fingerprint_tokens=fingerprints,\n",
    "        bond_dict=tokenizer.bond_dict,\n",
    "        strict_generation=True,\n",
    "        max_atoms=None,\n",
    "        similarity_threshold=0.5,\n",
    "        check_first_node=True,\n",
    "        check_atom_valence=False,\n",
    "        fix_aromatic_bond=False,\n",
    "        use_cache=False,\n",
    "        save_failed=True,  # save the generated partial result even the full generation failed\n",
    "        show_progress=True,\n",
    "        verbose=True,\n",
    "    )\n",
    "    all_results.extend(generation_result)\n",
    "\n",
    "print(\"Done.\")\n",
    "print(f\"#### Generated {len(all_results)} molecules\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b5324f8eb8e35de",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Decode Sequences back to SMILES"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "921df1d54d1bb705"
  },
  {
   "cell_type": "code",
   "source": [
    "from rdkit.Chem import Draw\n",
    "\n",
    "\n",
    "def show_mol_png(mol, size=(512, 512)):\n",
    "    img = Draw.MolToImage(mol, size=size)\n",
    "    img.show()\n",
    "    img.close()\n",
    "\n",
    "\n",
    "decoded_mols = []\n",
    "decoded_smiles = []\n",
    "\n",
    "for result in all_results:\n",
    "    if result is not None:\n",
    "        mol, smiles = tokenizer.decode(result)\n",
    "        decoded_mols.append(mol)\n",
    "        decoded_smiles.append(smiles)\n",
    "    else:\n",
    "        decoded_mols.append(None)\n",
    "        decoded_smiles.append(None)\n",
    "\n",
    "# visualize the first 10 results\n",
    "for i in range(10):\n",
    "    print(f\"Original SMILES {i}: {smiles_list[i]}\")\n",
    "    print(f\"Decoded SMILES {i}: {decoded_smiles[i]}\")\n",
    "    show_mol_png(decoded_mols[i])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef67a4e812de11e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c86d3fce01319503",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
